{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/igrapel/activation_functions/blob/main/testing_activation_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLcQ-jbjFU8x"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMDPNcDNg6t6",
        "outputId": "91bf95cb-f778-4921-9982-e12a7b486fef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting adversarial-robustness-toolbox\n",
            "  Downloading adversarial_robustness_toolbox-1.11.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 10.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn<1.1.0,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (57.4.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (4.64.0)\n",
            "Collecting numba>=0.53.1\n",
            "  Downloading numba-0.55.2-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 60.4 MB/s \n",
            "\u001b[?25hCollecting llvmlite<0.39,>=0.38.0rc1\n",
            "  Downloading llvmlite-0.38.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.5 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (3.1.0)\n",
            "Installing collected packages: llvmlite, numba, adversarial-robustness-toolbox\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed adversarial-robustness-toolbox-1.11.0 llvmlite-0.38.1 numba-0.55.2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#--------------- ACTIVATION FUNCTIONS ---------------#\n",
        "# https://stackoverflow.com/questions/43915482/how-do-you-create-a-custom-activation-function-with-keras\n",
        "# https://www.tensorflow.org/guide/autodiff\n",
        "#---------------Other possible Imports---------------#\n",
        "# from tensorflow.keras import backend as K\n",
        "# from tensorflow.python.util import nest\n",
        "# from keras.layers import Activation\n",
        "# from keras.utils.generic_utils import get_custom_objects\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.special import gamma\n",
        "\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "!pip install adversarial-robustness-toolbox\n",
        "from art.attacks.evasion import FastGradientMethod, CarliniL2Method, CarliniLInfMethod, BoundaryAttack, DeepFool\n",
        "from art.estimators.classification import TensorFlowV2Classifier\n",
        "\n",
        "from art.utils import load_dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeCfOqaDGQj0"
      },
      "source": [
        "#Importing MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MM5BPEMGStJ"
      },
      "outputs": [],
      "source": [
        "from art.utils import load_dataset\n",
        "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"mnist\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BoP2s0cGW4p"
      },
      "source": [
        "#Defining the ML Model\n",
        "First, we will evaluate with a LeNet-5 achitecture. We customized the activation functions using this. All we have to do is pass the activation function to this architecture. If nothing is passed, the default is tanh."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLQ7O6sBGeza"
      },
      "outputs": [],
      "source": [
        "def define_model(af=None): \n",
        "    model = Sequential()\n",
        "\n",
        "    # C1 convolutional layer \n",
        "#     model.add(layers.Conv2D(6, kernel_size=(5,5), strides=(1,1), activation='tanh', input_shape=(28,28,1), padding='same'))\n",
        "    if af == None: \n",
        "        model.add(layers.Conv2D(6, kernel_size=(5,5), strides=(1,1), activation='tanh', padding='same'))\n",
        "    else: \n",
        "        model.add(layers.Conv2D(6, kernel_size=(5,5), strides=(1,1), activation=af, padding='same', dynamic=True))\n",
        "\n",
        "    # S2 pooling layer\n",
        "    model.add(layers.AveragePooling2D(pool_size=(2,2), strides=(1,1), padding='valid'))\n",
        "\n",
        "    # C3 convolutional layer\n",
        "#     model.add(layers.Conv2D(16, kernel_size=(5,5), strides=(1,1), activation='tanh', padding='valid'))\n",
        "    if af == None: \n",
        "        model.add(layers.Conv2D(16, kernel_size=(5,5), strides=(1,1), activation='tanh', padding='valid'))\n",
        "    else: \n",
        "        model.add(layers.Conv2D(16, kernel_size=(5,5), strides=(1,1), activation=af, padding='valid', dynamic=True))\n",
        "\n",
        "    # S4 pooling layer\n",
        "    model.add(layers.AveragePooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "\n",
        "    # C5 fully connected convolutional layer\n",
        "    if af == None: \n",
        "        model.add(layers.Conv2D(120, kernel_size=(5,5), strides=(1,1), activation='tanh', padding='valid'))\n",
        "    else: \n",
        "        model.add(layers.Conv2D(120, kernel_size=(5,5), strides=(1,1), activation=af, padding='valid', dynamic=True))\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # FC6 fully connected layer\n",
        "    if af == None: \n",
        "        model.add(layers.Dense(84, activation='tanh'))\n",
        "    else: \n",
        "        model.add(layers.Dense(84, activation=af, dynamic=True))\n",
        "\n",
        "    # Output layer with softmax activation\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "def train_step(model, images, labels):\n",
        "    loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training=True)\n",
        "        loss = loss_object(labels, predictions)\n",
        "        \n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    \n",
        "def train_model(model, x_train, y_train, x_test, y_test, eps=10, batch=128, lr=0.01, filename=None):\n",
        "    loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "\n",
        "    classifier = TensorFlowV2Classifier(model=model,\n",
        "                                        clip_values=(min_, max_), \n",
        "                                        input_shape=x_train.shape[1:], \n",
        "                                        nb_classes=10,  \n",
        "                                        train_step=train_step,\n",
        "                                        loss_object=loss_object)\n",
        "    print('...created classifier')\n",
        "    hist = classifier.fit(x_train, y_train, nb_epochs=eps, batch_size=batch)\n",
        "    print('...finished training')\n",
        "    \n",
        "    # # Evaluate the classifier on the test set\n",
        "    preds = np.argmax(classifier.predict(x_test), axis=1)\n",
        "    acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
        "    print(\"Test accuracy: %.2f%%\\n\" % (acc * 100))\n",
        "    \n",
        "    loss = classifier.compute_loss(x_train, y_train, training_mode=True)\n",
        "    print('Training loss: ', loss)\n",
        "\n",
        "    return classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvFA_gSaGhLd"
      },
      "source": [
        "#Defining the attacks\n",
        "Again, we are just using the Adversarial Robustness Toolbox so we don't have to implement the different attacks ourselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I55E7vosGivi"
      },
      "outputs": [],
      "source": [
        "def fgsm_attack(classifier, x_test, y_test, eps=0.2):\n",
        "    epsilon = eps  # Maximum perturbation\n",
        "    adv_crafter = FastGradientMethod(classifier, eps=epsilon)\n",
        "    print('...creating adversarial examples')\n",
        "    x_test_adv = adv_crafter.generate(x=x_test)\n",
        "\n",
        "    # Evaluate the classifier on the adversarial examples\n",
        "    preds = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
        "    acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
        "    print(\"Test accuracy on adversarial sample: %.2f%%\" % (acc * 100))\n",
        "    \n",
        "def boundary_attack(classifier, x_test, y_test):\n",
        "    adv_crafter = BoundaryAttack(classifier, targeted=False, max_iter=0, delta=0.001, epsilon=0.001, init_size=5)\n",
        "    print('...creating adversarial examples')\n",
        "    x_test_adv = adv_crafter.generate(x=x_test, y=y_test)\n",
        "\n",
        "    # Evaluate the classifier on the adversarial examples\n",
        "    preds = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
        "    acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
        "    print(\"Test accuracy on adversarial sample: %.2f%%\" % (acc * 100))\n",
        "    \n",
        "def deepfool_attack(classifier, x_test, y_test):\n",
        "    adv_crafter = DeepFool(classifier)\n",
        "    print('...creating adversarial examples')\n",
        "    x_test_adv = adv_crafter.generate(x=x_test)\n",
        "\n",
        "    # Evaluate the classifier on the adversarial examples\n",
        "    preds = np.argmax(classifier.predict(x_test_adv), axis=1)\n",
        "    acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
        "    print(\"Test accuracy on adversarial sample: %.2f%%\" % (acc * 100))\n",
        "\n",
        "def get_successful_test(classifier, x_test, y_test):\n",
        "    preds = np.argmax(classifier.predict(x_test), axis=1)\n",
        "    acc = np.sum(preds == np.argmax(y_test, axis=1)) / y_test.shape[0]\n",
        "    print(\"Original test accuracy: %.2f%%\" % (acc * 100))\n",
        "    \n",
        "    preds = np.argmax(classifier.predict(x_test), axis=1)\n",
        "    correct = np.nonzero(preds == np.argmax(y_test, axis=1))\n",
        "\n",
        "    eval_x_test = x_test[correct]\n",
        "    eval_y_test = y_test[correct]\n",
        "\n",
        "    eval_x_test_final = eval_x_test[:1000]\n",
        "    print(eval_x_test_final.shape)\n",
        "    eval_y_test_final = eval_y_test[:1000]\n",
        "    print(eval_y_test_final.shape)\n",
        "    \n",
        "    preds = np.argmax(classifier.predict(eval_x_test_final), axis=1)\n",
        "    acc = np.sum(preds == np.argmax(eval_y_test_final, axis=1)) / eval_y_test_final.shape[0]\n",
        "    print(\"Test set of correctly predicted (benign): %.2f%%\" % (acc * 100))\n",
        "    \n",
        "    return eval_x_test_final, eval_y_test_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYSKK6fdGmaK"
      },
      "source": [
        "#Testing Generalized Gamma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSOfmuu8GvuU",
        "outputId": "93225251-5a3e-4ded-fa27-8b5dec61dc8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "...created classifier\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "HYPERPARAMETERS\n",
        "'''\n",
        "a = 1 # alpha\n",
        "b = 3 # beta\n",
        "c = 3 # gamma\n",
        "mu = -2.61  # mu\n",
        "sf = 1.17 # scale factor\n",
        "\n",
        "'''\n",
        "FUNCTIONS\n",
        "'''\n",
        "def generalized_gamma(x):\n",
        "    x = tf.math.divide(x-mu, b)\n",
        "    func = tf.math.divide(tf.math.exp(-x**c)*c*x**((c*a)-1), gamma(a))    \n",
        "    return tf.where(x>0, tf.math.divide(func, sf), 0)\n",
        "def gamma_derivative(x):\n",
        "    x = tf.Variable(x, name='x')\n",
        "    with tf.GradientTape(persistent=True) as tape: \n",
        "        y = tf.constant(generalized_gamma(x), dtype='float32')\n",
        "    dy_dx = tape.gradient(y, x)\n",
        "    return dy_dx\n",
        "\n",
        "@tf.custom_gradient\n",
        "def gamma_activation(x):\n",
        "    def grad(dy):\n",
        "        return gamma_derivative(x) * dy\n",
        "\n",
        "    result = generalized_gamma(x)\n",
        "    return result, grad\n",
        "model = define_model(gamma_activation)\n",
        "classifier = train_model(model, x_train, y_train, x_test, y_test, eps=15)\n",
        "\n",
        "eval_x_test, eval_y_test = get_successful_test(classifier, x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNfxfhjatEdZ"
      },
      "source": [
        "#Fast Gradient Sign Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FygoDXStGoI"
      },
      "outputs": [],
      "source": [
        "for epsilon in [0.02, 0.04, 0.06, 0.2, 0.4]:\n",
        "    fgsm_attack(classifier, eval_x_test, eval_y_test, eps=epsilon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z66e7tGjtJZY"
      },
      "source": [
        "#Boundary Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRcZulA9tOsb"
      },
      "outputs": [],
      "source": [
        "boundary_attack(classifier, eval_x_test, eval_y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO--0sWQtTHg"
      },
      "source": [
        "#DeepFool Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QVec4BftU_w"
      },
      "outputs": [],
      "source": [
        "deepfool_attack(classifier, eval_x_test, eval_y_test)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "testing-activation-functions.ipynb",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMUs1vqeY/g5niTDeRkFxqF",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}